{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14af25c9-263c-428f-8c2f-c8c160082eca",
   "metadata": {},
   "source": [
    "## Motivation \n",
    "\n",
    "\"Sunshine, temperature, and rain have a significant impact on dailysales, particularly in the summer, on weekends, and on days with extreme weather.\" \n",
    "\n",
    "\"Using weather forecasts, we have sig-nificantly improved sales forecast accuracy. We find that including weather data in the sales forecast model can lead tofewer sales forecast errors, reducing them by, on average, 8.6% to 12.2% and up to 50.6% on summer weekends\"\n",
    "\n",
    "\n",
    "**Goal**\n",
    "\n",
    "1. Get Temperature Data \n",
    "2. Get Caily sunshine cat data (sunshine, cloudy, raining)\n",
    "    - raining includes fog, snow and heavy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "415ddef2-2eca-4c8f-b5a2-716f78ca6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "# Basics\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Wetterdiesnt, API for deutscher wetterdienst (dwd)\n",
    "from wetterdienst.provider.dwd.observation import DwdObservationRequest, \\\n",
    "    DwdObservationPeriod, DwdObservationResolution, DwdObservationParameter, DwdObservationDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5fa19-4bd0-4842-9a58-b116988b639b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wetterdienst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc75daa-0db5-48ba-ba7a-7ea61f09d088",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get all Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fade587-c537-4729-aa01-89eec2380dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "print(\"All available parameters\")\n",
    "print(\n",
    "    DwdObservationRequest.discover()\n",
    ")\n",
    " selection\n",
    " print(\"Selection of daily data\")\n",
    "print(\n",
    "    DwdObservationRequest.discover(\n",
    "        filter_=DwdObservationResolution.DAILY\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db9efc-ebc2-467c-b0dd-6499d259d456",
   "metadata": {},
   "source": [
    "List of variables I want:\n",
    "\n",
    "sunshine_duration (in min)\n",
    "TEMPERATURE_AIR_MEAN_200\n",
    "temperature_air_min_200\n",
    "temperature_air_max_200\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82897ef-da43-468b-bf92-d2bfddbdcfe5",
   "metadata": {},
   "source": [
    "Select weather station per Bundesland:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8380299-51f1-46bf-8eac-d2021726b043",
   "metadata": {},
   "source": [
    "### Weather per state code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47816a2a-2fa0-4f1b-85f0-d42601a09a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts average temperature, average percipitation and sunshine duration from dwd api \n",
    "\n",
    "def get_weather_data(start_date, end_date, station_id):\n",
    "    \n",
    "    request = DwdObservationRequest(\n",
    "    parameter=[\n",
    "         DwdObservationParameter.DAILY.TEMPERATURE_AIR_MEAN_200,\n",
    "        DwdObservationParameter.DAILY.PRECIPITATION_HEIGHT,\n",
    "        DwdObservationParameter.DAILY[\"SUNSHINE_DURATION\"]\n",
    "    ],\n",
    "    resolution=DwdObservationResolution.DAILY,\n",
    "    start_date=start_date,  # if not given timezone defaulted to UTC\n",
    "    end_date=end_date\n",
    "    #period=DwdObservationPeriod.HISTORICAL\n",
    "    ).filter_by_station_id(station_id=station_id)\n",
    "    \n",
    "    station_data = request.values.all().df\n",
    "    \n",
    "    return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbbd9e-a4ca-461a-b61e-129acca3dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 16 datasets per state in germany. name datasets according to state name \n",
    "\n",
    "# Data Manually colelcted \n",
    "cities = ['Hamburg-Fuhlsbüttel', 'Schleswig', 'Bremen', 'Berlin-Dahlem (FU)', 'Potsdam', 'Schwerin', 'Hannover', \n",
    "          'Dresden-Klotzsche', 'Magdeburg', 'Erfurt-Weimar', 'Düsseldorf', 'Stuttgart-Echterdingen', 'Frankfurt/Main', \n",
    "          'Saarbrücken-Ensheim', 'Trier-Petrisberg', 'München-Stadt']\n",
    "\n",
    "station_id = [1975, 4466, 691, 403, 3987, 4625, 2014, 1048, 3126, 1270, 1078, 4931, 1420, 4336, 5100, 3379]\n",
    "\n",
    "# List all available stations\n",
    "request = DwdObservationRequest(\n",
    "    parameter=DwdObservationDataset.PRECIPITATION_MORE,\n",
    "    resolution=DwdObservationResolution.DAILY,\n",
    "    period=DwdObservationPeriod.HISTORICAL\n",
    ")\n",
    "\n",
    "# Save df \n",
    "stations = request.all().df\n",
    "\n",
    "# Select stations based on station names that are saved in \"cities\"\n",
    "selected_stations = stations[stations.name.isin(cities)]\n",
    "\n",
    "# Change names of station names to avoid errors\n",
    "selected_stations['state'] = selected_stations['state'].str.replace('-','_')\n",
    "selected_stations['state'] = selected_stations['state'].str.replace('ü','ue')\n",
    "selected_stations['state'] = selected_stations['state'].str.replace('/','_')\n",
    "\n",
    "selected_stations.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "# Create Data Frames \n",
    "\n",
    "# The code selects the statename from the data frame selected stations and assigns the corresponding dataframe based on station_id \n",
    "for i in range(16):\n",
    "    name = selected_stations[\"state\"].tolist()[i]\n",
    "    exec(f\"{name} = get_weather_data('2015-12-30', '2022-12-31', ([int(x) for x in selected_stations['station_id'].tolist()][i], ))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6c890-7864-4151-8c76-c53e7b92357d",
   "metadata": {},
   "source": [
    "#### Create Features \n",
    "\n",
    "1. 3 columns for each parameter (temperature_air_mean_200, sunshine_duration, percipitation (rain))\n",
    "2. Temperature: scale 1-10 for each month average (look at paper)\n",
    "3. Sunshine -> convert into hours /3600\n",
    "4. Percipitation (look into paper, 0 for no rain -> 1-10 percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b341bf-23f9-4bd8-b8bc-7c08e3cdd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 columns \n",
    "\n",
    "def pivot_weather(df):\n",
    "    df_pivot = df.pivot_table(index=[\"date\",\"state\",\"station_id\"], columns= [\"parameter\"], values=\"value\").reset_index()\n",
    "    df_pivot[\"station_id\"] = df[\"station_id\"]\n",
    "    #df_pivot[\"state\"] = df[\"state\"]\n",
    "    return df_pivot \n",
    "\n",
    "# test\n",
    "#Brandenburg[\"state\"] = \"Brandenburg\"\n",
    "#Brandenburg_p = pivot_weather(Brandenburg)\n",
    "#Brandenburg_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b058e8f-a390-4780-9927-84158eb4b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sunshine \n",
    "\n",
    "# Change class borders to allow 10 classes\n",
    "def jitter(a_series, noise_reduction=1000000):\n",
    "    return (np.random.random(len(a_series))*a_series.std()/noise_reduction)-(a_series.std()/(2*noise_reduction))\n",
    "\n",
    "def sunshine_hours(df):\n",
    "    df[\"sunshine_duration_h\"] = df[\"sunshine_duration\"]/3600\n",
    "    \n",
    "    df[\"suns_classes\"] = df.groupby(df[\"date\"].dt.month)[\"sunshine_duration_h\"].transform(\n",
    "    lambda x: pd.qcut(x + jitter(x), 10, labels=range(0,10)))\n",
    "    \n",
    "    df.sunshine_duration.drop\n",
    "    \n",
    "    return df\n",
    "\n",
    "# test\n",
    "#sunshine_hours(Brandenburg_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449062b-37b5-4cff-b8c8-73f50cba1b00",
   "metadata": {},
   "source": [
    "To make the different months more comparable, we compute relative weather classes, which we refer to as scores. More specifically, we build monthly deciles using data from 1997 to 2012. The weather score expresses the relative classification of a weather parameter on 1 day compared with all of the days in that month across the 15-year estimation sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9facc6-ba05-4683-9000-16601d1de058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "\n",
    "def temp_classes(df):\n",
    "    df[\"temp_classes\"] = df.groupby(df[\"date\"].dt.month)[\"temperature_air_mean_200\"].transform(\n",
    "                     lambda x: pd.qcut(x, 10, labels=range(0,10)))\n",
    "    return df\n",
    "    \n",
    "# test\n",
    "#temp_classes(Brandenburg_p).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4bf18-606c-49f0-b51d-3bb670e73a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rain \n",
    "\n",
    "# introduce a minimal amount of noise, which will artificially create unique bin edges. (source: stackoverflow)\n",
    "def jitter(a_series, noise_reduction=1000000):\n",
    "    return (np.random.random(len(a_series))*a_series.std()/noise_reduction)-(a_series.std()/(2*noise_reduction))\n",
    "\n",
    "\n",
    "def rain_classes(df):\n",
    "    \n",
    "    # Zero Values are NaN now, so qcut does ignore these values (more than 50% of values are 0)\n",
    "    df[\"precipitation_height\"].replace(to_replace=0, value=np.nan, inplace=True)\n",
    "    \n",
    "    # Create monthly percentiles bases on remaining values \n",
    "    df[\"rain_classes\"] = df.groupby(df[\"date\"].dt.month)[\"precipitation_height\"].transform(\n",
    "    lambda x: pd.qcut(x + jitter(x), 10, labels=range(0,10)))\n",
    "    \n",
    "    # Fill Na Values with zeros \n",
    "    df['rain_classes'] = df['rain_classes'].fillna(0)\n",
    "    df[\"precipitation_height\"] =  df[\"precipitation_height\"].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# test\n",
    "#rain_classes(Brandenburg_p).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe57e7-a56c-40af-b29f-e2a7cce5138f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarise \n",
    "def all_weather_features(df):\n",
    "    \n",
    "    # Create 3 columns \n",
    "    df_p = pivot_weather(df)\n",
    "    \n",
    "    # fillna with mean values \n",
    "    columns_with_na = df_p.columns[df_p.isna().any()].tolist()\n",
    "    df_p[columns_with_na] = df_p[columns_with_na].apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "    \n",
    "    # Sunshine\n",
    "    df_p = sunshine_hours(df_p)\n",
    "    # Temperature\n",
    "    df_p = temp_classes(df_p)\n",
    "    # Rain\n",
    "    df_p = rain_classes(df_p)\n",
    "    \n",
    "    return df_p\n",
    "\n",
    "#test\n",
    "#Brandenburg_p = all_weather_features(Brandenburg)\n",
    "#Brandenburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25334e18-5546-4b09-996f-7f23415a911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get everything together\n",
    "\n",
    "# Names of all dfs\n",
    "dfs = [Brandenburg, Berlin, Bremen, Sachsen, Nordrhein_Westfalen, Thueringen, Hessen, Hamburg, Niedersachsen, Sachsen_Anhalt, Bayern, Saarland, Schleswig_Holstein, Mecklenburg_Vorpommern, Baden_Wuerttemberg, Rheinland_Pfalz]\n",
    "\n",
    "# Empty Dictionary\n",
    "df_dict = {}\n",
    "\n",
    "#\n",
    "for df, u in zip(dfs, selected_stations[\"state\"].tolist()):\n",
    "    # Extract the name of the data frame\n",
    "    name = u\n",
    "    # Add the data frame to the dictionary with the name as the key\n",
    "    df_dict[name] = df\n",
    "    \n",
    "#df_dict\n",
    "\n",
    "for key, df in df_dict.items():\n",
    "    df_dict[key] = df.assign(state=key)\n",
    "\n",
    "#Finally, to concatenate all of the data frames together, I use concat function and pass in the list of data frames as the argument:\n",
    "df_concat = pd.concat([df for df in df_dict.values()]).reset_index()\n",
    "\n",
    "state_df = all_weather_features(df_concat)\n",
    "\n",
    "# Make station_id, suns_classes, temp_classes and rain_classes an integer\n",
    "state_df[['station_id', \n",
    "    'suns_classes', \n",
    "    'temp_classes', \n",
    "    'rain_classes']] = state_df[['station_id', \n",
    "                           'suns_classes', \n",
    "                           'temp_classes', \n",
    "                           'rain_classes']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66d971-cb79-4856-bc68-79ac393cb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary for Germany \n",
    "\n",
    "# Groupby mean and date \n",
    "germany_df = state_df.groupby(\"date\").mean()\n",
    "germany_df[\"state\"] = \"Deutschland\"\n",
    "germany_df[\"station_id\"] = 99999\n",
    "\n",
    "# Create weather classes with same method as before\n",
    "\n",
    "# Sunshine\n",
    "germany_df = sunshine_hours(germany_df.reset_index())\n",
    "# Temperature\n",
    "germany_df = temp_classes(germany_df)\n",
    "# Rain\n",
    "germany_df = rain_classes(germany_df)\n",
    "\n",
    "germany_df[['station_id', \n",
    "    'suns_classes', \n",
    "    'temp_classes', \n",
    "    'rain_classes']] = germany_df[['station_id', \n",
    "                           'suns_classes', \n",
    "                           'temp_classes', \n",
    "                           'rain_classes']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aed169-5682-4683-825e-2da25d370a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = state_df.merge(germany_df, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2030d6f-aa8e-40a9-bc25-582dfac5c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df as csv\n",
    "\n",
    "final_df.set_index(\"date\").to_csv(\"../data/intermediate/weather.csv\")\n",
    "\n",
    "# test\n",
    "#pd.read_csv(\"../data/intermediate/weather.csv\").info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
